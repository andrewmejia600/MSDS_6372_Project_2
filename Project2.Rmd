---
title: "DS6372_Project2"
author: "AndrewMejia"     
date: "3/15/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.


```{r}

library(ggplot2)
library(GGally)
library(dplyr)
library(caret)
library(plotly)
library(ResourceSelection)
library(car)
library(ROCR)
library(MASS)
library(stringr)
library(glmnet)
library(bestglm)
library(rms)


Bank_mrkt_data  = read.csv(file.choose(),header = TRUE, sep = ';')

```

```{r}


#Test Train Splits 

#Down Sampling 
set.seed(1234)
Bank_mrkt_data_dwn_sample = downSample(Bank_mrkt_data[,1:20], Bank_mrkt_data[,21])

#Controling Sampling by modifying the p in the create partition for creating the test train splits from the downsampled data for training. 
set.seed(1234)
Bank_mrkt_data_partition_idx = createDataPartition(Bank_mrkt_data_dwn_sample$Class, p=.5, list = FALSE, times = 1)


Bank_mrkt_data_partition_train = Bank_mrkt_data_dwn_sample[Bank_mrkt_data_partition_idx,]
Bank_mrkt_data_partition_test = Bank_mrkt_data_dwn_sample[-Bank_mrkt_data_partition_idx,]

#Removing Row Number Partitions indices 
row.names(Bank_mrkt_data_partition_train) = NULL
row.names(Bank_mrkt_data_partition_test) = NULL 



#LDA on continous variables --- Highest Accuracy 

lda_analysis = lda(Class ~ age +  duration + campaign + pdays + previous + emp.var.rate + cons.price.idx + cons.conf.idx + euribor3m + nr.employed, data = Bank_mrkt_data_partition_train)

pred = predict(lda_analysis,newdata=Bank_mrkt_data_partition_test)$class
Truth = Bank_mrkt_data_partition_test$Class

table(pred)

confusionMatrix(table(pred, Truth))



```

PCA Analysis 
```{r}
#Balanced test train split
pairs(Bank_mrkt_data_partition_train[, c(1,11,12,13,14,16,17,18,19,20)], col = Bank_mrkt_data_partition_train$Class)

#Not balanced, only 11% is yes 
pairs(Bank_mrkt_data[, c(1,11,12,13,14,16,17,18,19,20)], col = Bank_mrkt_data$y)


#promising 
bank_train_reduced = Bank_mrkt_data[,c(1,11,12,16)]

#Also promising correlated vars 
#bank_train_reduced = Bank_mrkt_data[,c(1,11,16)]

pairs(bank_train_reduced, col = Bank_mrkt_data$y)

pc.result = prcomp(bank_train_reduced,scale.=TRUE)
pc.scores = pc.result$x

pc.result
pairs(pc.scores)


```

```{r}

par(mfrow=c(1,2))
eigenvals<-(pc.result$sdev)^2
plot(1:dim(bank_train_reduced)[2],eigenvals/sum(eigenvals),type="l",main="Scree Plot",ylab="Prop. Var. Explained")
cumulative.prop<-cumsum(eigenvals/sum(eigenvals))
plot(1:dim(bank_train_reduced)[2],cumulative.prop,type="l",main="Cumulative proportion",ylim=c(0,1))


```

```{r}
par(mfrow=c(1,1))

##Minimal PCAs needed to have cumulative explained variance higher than .9

minimal.pca <- which(cumulative.prop>0.9)[1]
minimal.pca
```

Ading the response column to the PCs 
```{r}
pc.scores = data.frame(pc.scores)
#pc.scores$Class = Bank_mrkt_data_partition_train$Class
pc.scores$Class = Bank_mrkt_data$y

ggplot(data = pc.scores, aes(x = PC1, y = PC2 )) + geom_point(aes(col=pc.scores$Class), size = 1, shape = '*') + ggtitle("PCA of Deposits ")

ggplot(data = pc.scores, aes(x = PC2, y = PC3 )) + geom_point(aes(col=pc.scores$Class), size = 1, shape = '*') + ggtitle("PCA of Deposits ")


ggplot(data = pc.scores, aes(x = PC3, y = PC4 )) + geom_point(aes(col=pc.scores$Class), size = 1, shape = '*') + ggtitle("PCA of Deposits ")

```

#Logistic Regression Full list of variables -- HL GOF test pvalue < 2.2e-16 not a good fit
#Need to use for forward selection 

```{r}


main.logr<-glm(Class ~ age + job + marital + education + default + housing + loan + contact + month + day_of_week + duration + campaign + pdays + previous + poutcome + emp.var.rate + cons.price.idx + cons.conf.idx + euribor3m + nr.employed ,data=Bank_mrkt_data_partition_train ,family=binomial(link='logit') )

summary(main.logr)
exp(cbind("Odds ratio" = coef(main.logr), confint.default(main.logr, level = 0.95)))
#vif(logr)

plot(main.logr, pch = 16)

main.logr$aic


hoslem.test(main.logr$y, fitted(main.logr), g=10)

pred = predict(main.logr, newdata = Bank_mrkt_data_partition_test, type="response")

Bank_mrkt_data_partition_test['Pred_Out'] = as.factor(ifelse(pred>.50, "yes", "no"))

Truth = Bank_mrkt_data_partition_test$Class
Predt = Bank_mrkt_data_partition_test$Pred_Out

table(Predt)

confusionMatrix(table(Predt, Truth))

```



#Winning Base Model 
```{r}

main.logr_l_2 = glm(Class ~ duration + cons.price.idx + contact + poutcome,data=Bank_mrkt_data_partition_train ,family=binomial(link='logit'))


#Looking at influence points with LRM model to look at residuals 

resid_lev_fit = lrm(Class ~ duration + cons.price.idx + contact + poutcome,data=Bank_mrkt_data_partition_train, x = TRUE,y = TRUE )

#See too many observations to exclude in different variables, creates a highly biased model
if_point = which.influence(resid_lev_fit, cutoff = 0.0055)

step(main.logr_l_2,
     scope = list(upper=main.logr),
     direction="forward",
     test="Chisq",
     data=Bank_mrkt_data_partition_train)
  
plot(main.logr_l_2)

exp(cbind("Odds ratio" = coef(main.logr_l_2), confint.default(main.logr_l_2, level = 0.95)))

coefficients(main.logr_l_2)

main.logr_l_2

summary(main.logr_l_2)

hoslem.test(main.logr_l_2$y, fitted(main.logr_l_2), g=10)

main.logr_l_2$aic

pred = predict(main.logr_l_2, newdata = Bank_mrkt_data_partition_test, type="response")

Bank_mrkt_data_partition_test['Pred_Out'] = as.factor(ifelse(pred>.50, "yes", "no"))

Truth = Bank_mrkt_data_partition_test$Class
Predt = Bank_mrkt_data_partition_test$Pred_Out

table(Predt)

confusionMatrix(table(Predt, Truth))



```

# L3_is final model for prediction with highest accuracy and lowest AIC yields best AUC results 
#Good overall prediction score especially when looking at ROC curves not much gain in complex models, pretty good accuracy in truth tables for main model-- not a good fit to data -- Removing outliers did not yield much gain in model performance. 
```{r}


main.logr_l_3 = glm(Class ~ duration + month + emp.var.rate + cons.price.idx + contact + poutcome + campaign + euribor3m + cons.conf.idx + job + education ,data=Bank_mrkt_data_partition_train ,family=binomial(link='logit'))

#Looking at influence and how many observations to exclude, still would create a highly biased model 

resid_lev_fit = lrm(Class ~ duration + month + emp.var.rate + cons.price.idx + contact + poutcome + campaign + euribor3m + cons.conf.idx + job + education,data=Bank_mrkt_data_partition_train, x = TRUE,y = TRUE )

if_point = which.influence(resid_lev_fit, cutoff = 0.01)


step(main.logr_l_3,
     scope = list(upper=main.logr),
     direction="forward",
     test="Chisq",
     data=Bank_mrkt_data_partition_train)

exp(cbind("Odds ratio" = coef(main.logr_l_3), confint.default(main.logr_l_3, level = 0.95)))

main.logr_l_3$aic

summary(main.logr_l_3)

coefficients(main.logr_l_3)

hoslem.test(main.logr_l_3$y, fitted(main.logr_l_3), g=10)
plot(main.logr_l_3)

pred = main.logr_l_3$fitted.values

Bank_mrkt_data_partition_train['Pred_Out'] = as.factor(ifelse(pred>.50, "yes", "no"))

Truth = Bank_mrkt_data_partition_train$Class
Predt = Bank_mrkt_data_partition_train$Pred_Out

confusionMatrix(table(Predt, Truth))



#validation against test split
  

pred = predict(main.logr_l_3, newdata = Bank_mrkt_data_partition_test, type="response")

Bank_mrkt_data_partition_test['Pred_Out'] = as.factor(ifelse(pred>.50, "yes", "no"))

Truth = Bank_mrkt_data_partition_test$Class
Predt = Bank_mrkt_data_partition_test$Pred_Out

table(Predt)

confusionMatrix(table(Predt, Truth))




```

#Complex Model 
```{r}
logr.model.complex = glm(Class ~ duration + month + emp.var.rate + cons.price.idx + contact + poutcome + campaign + euribor3m + cons.conf.idx + job + education + duration:education + duration:job ,data=Bank_mrkt_data_partition_train ,family=binomial(link='logit'))
step(main.logr_l_3,
     scope = list(upper=logr.model.complex),
     direction="forward",
     test="Chisq",
     data=Bank_mrkt_data_partition_train)
hoslem.test(logr.model.complex$y, fitted(logr.model.complex), g=10)

logr.model.complex$aic

summary(logr.model.complex)

plot(logr.model.complex)

logr.model.complex$aic

pred = predict(logr.model.complex, newdata = Bank_mrkt_data_partition_test, type="response")

Bank_mrkt_data_partition_test['Pred_Out'] = as.factor(ifelse(pred>.50, "yes", "no"))

Truth = Bank_mrkt_data_partition_test$Class
Predt = Bank_mrkt_data_partition_test$Pred_Out

table(Predt)

confusionMatrix(table(Predt, Truth))


```



#ROC Curves need to be in GLMNET inputs matrices 
```{r}
#Base Model AUC results 
Bank_mrkt_data_partition_formula = as.formula(Class ~ duration  + cons.price.idx + contact + poutcome)

Bank_mrkt_data_partition_train_mat.x = model.matrix(Bank_mrkt_data_partition_formula, Bank_mrkt_data_partition_train)
Bank_mrkt_data_partition_train_mat.y = as.matrix(Bank_mrkt_data_partition_train[,21], ncol=1) 

Bank_mrkt_data_partition_test_mat.x = model.matrix(Bank_mrkt_data_partition_formula, Bank_mrkt_data_partition_test)
Bank_mrkt_data_partition_test_mat.y = as.matrix(Bank_mrkt_data_partition_test[,21], ncol=1) 


log_glmnet = glmnet(Bank_mrkt_data_partition_train_mat.x, Bank_mrkt_data_partition_train_mat.y, family = "binomial")

plot(log_glmnet)

coef(log_glmnet)

cvfit =  cv.glmnet(Bank_mrkt_data_partition_train_mat.x, Bank_mrkt_data_partition_train_mat.y, family = "binomial", type.measure = "class", nlambda = 1000)

plot(cvfit)
coef(cvfit, s = "lambda.min")


fit.pred = predict(cvfit, newx =  Bank_mrkt_data_partition_train_mat.x, type = "response")

pred  = prediction(fit.pred[,1], Bank_mrkt_data_partition_train_mat.y)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train = performance(pred, measure = "auc")
auc.train =  auc.train@y.values

#Plot ROC
plot(roc.perf)
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .40, y = .6,paste("AUC = ", round(auc.train[[1]],3), sep = ""))



fit.pred.test = predict(cvfit, newx =  Bank_mrkt_data_partition_test_mat.x, type = "response")

pred.test  = prediction(fit.pred.test[,1], Bank_mrkt_data_partition_test_mat.y)
roc.perf = performance(pred.test, measure = "tpr", x.measure = "fpr")
auc.train = performance(pred.test, measure = "auc")
auc.train =  auc.train@y.values

#Plot ROC
plot(roc.perf)
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .40, y = .6,paste("AUC = ", round(auc.train[[1]],3), sep = ""))

```

```{r}


#Winning model AUC results 
Bank_mrkt_data_partition_formula = as.formula(Class ~ duration + month + emp.var.rate + cons.price.idx + contact + poutcome + campaign + euribor3m + cons.conf.idx + job + education)
Bank_mrkt_data_partition_train_mat.x = model.matrix(Bank_mrkt_data_partition_formula, Bank_mrkt_data_partition_train)
Bank_mrkt_data_partition_train_mat.y = as.matrix(Bank_mrkt_data_partition_train[,21], ncol=1) 

Bank_mrkt_data_partition_test_mat.x = model.matrix(Bank_mrkt_data_partition_formula, Bank_mrkt_data_partition_test)
Bank_mrkt_data_partition_test_mat.y = as.matrix(Bank_mrkt_data_partition_test[,21], ncol=1) 


log_glmnet = glmnet(Bank_mrkt_data_partition_train_mat.x, Bank_mrkt_data_partition_train_mat.y, family = "binomial")

plot(log_glmnet)

coef(log_glmnet)

cvfit =  cv.glmnet(Bank_mrkt_data_partition_train_mat.x, Bank_mrkt_data_partition_train_mat.y, family = "binomial", type.measure = "class", nlambda = 1000)

plot(cvfit)
coef(cvfit, s = "lambda.min")


fit.pred = predict(cvfit, newx =  Bank_mrkt_data_partition_train_mat.x, type = "response")

pred  = prediction(fit.pred[,1], Bank_mrkt_data_partition_train_mat.y)
roc.perf = performance(pred, measure = "tpr", x.measure = "fpr")
auc.train = performance(pred, measure = "auc")
auc.train =  auc.train@y.values

#Plot ROC
plot(roc.perf)
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .40, y = .6,paste("AUC = ", round(auc.train[[1]],3), sep = ""))



fit.pred.test = predict(cvfit, newx =  Bank_mrkt_data_partition_test_mat.x, type = "response")

pred.test  = prediction(fit.pred.test[,1], Bank_mrkt_data_partition_test_mat.y)
roc.perf = performance(pred.test, measure = "tpr", x.measure = "fpr")
auc.train = performance(pred.test, measure = "auc")
auc.train =  auc.train@y.values

#Plot ROC
plot(roc.perf)
abline(a=0, b= 1) #Ref line indicating poor performance
text(x = .40, y = .6,paste("AUC = ", round(auc.train[[1]],3), sep = ""))





```

```{r}
#McNemar's Test for competing models 

#Base model vs winning model 
performance_comp_mat_bse_model_winning = matrix(c(2573, 2067,2282,2358), nrow = 2, dimnames = list("BMdl" = c("No", "Yes"), "WMdl"= c("No", "Yes")))

mcnemar.test(performance_comp_mat_bse_model_winning)


#Complex Model vs winning Model 
performance_comp_mat_compl_model_winning = matrix(c(2277,2363,2282,2358), nrow = 2, dimnames = list("CMdl" = c("No", "Yes"), "WMdl"= c("No", "Yes")))

mcnemar.test(performance_comp_mat_compl_model_winning)

#LDA Model vs winning Model 
performance_comp_mat_lda_model_winning = matrix(c(2452,2188,2282,2358), nrow = 2, dimnames = list("CMdl" = c("No", "Yes"), "WMdl"= c("No", "Yes")))

mcnemar.test(performance_comp_mat_lda_model_winning)


  
```



